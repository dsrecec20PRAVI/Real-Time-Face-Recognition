{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Učitavanje potrebnih biblioteka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import roc_curve\n",
    "from itertools import combinations\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from PIL import Image\n",
    "import timm\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Učitavanje seta podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_folder = '../data/people/'\n",
    "train_folder = '../data/train/'\n",
    "valid_folder = '../data/valid/'\n",
    "test_folder = '../data/test/'\n",
    "\n",
    "# Remove existing train, valid, and test folders (if they exist)\n",
    "for folder in [train_folder, valid_folder, test_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)  # Delete the folder and its contents\n",
    "\n",
    "# Create destination folders\n",
    "for folder in [train_folder, valid_folder, test_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for class_name in os.listdir(main_data_folder):\n",
    "    class_path = os.path.join(main_data_folder, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue  # Skip non-folder items\n",
    "\n",
    "    # List all images in the class folder\n",
    "    images = os.listdir(class_path)\n",
    "\n",
    "    # Create class subfolders in train, valid, and test directories\n",
    "    os.makedirs(os.path.join(train_folder, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(valid_folder, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(test_folder, class_name), exist_ok=True)\n",
    "\n",
    "    # Ensure at least 1 image in test and 1 in validation\n",
    "    test_images = images[:15]  # First image for testing\n",
    "    valid_images = images[15:30]  # Second image for validation\n",
    "    train_images = images[30:]  # Remaining images for training\n",
    "\n",
    "    # Move images to respective folders\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(train_folder, class_name, img))\n",
    "    for img in valid_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(valid_folder, class_name, img))\n",
    "    for img in test_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(test_folder, class_name, img))\n",
    "\n",
    "    print(f\"Class {class_name}: {len(train_images)} train, {len(valid_images)} valid, {len(test_images)} test images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = '../data/train/'\n",
    "valid_folder = '../data/valid/'\n",
    "test_folder = '../data/test/'\n",
    "\n",
    "train_dataset = FaceDataset(train_folder, transform=transform)\n",
    "val_dataset = FaceDataset(valid_folder, transform=transform)\n",
    "test_dataset = FaceDataset(test_folder, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FaceClassifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(FaceClassifier, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Reduces spatial dimensions by half\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # Reduces spatial dimensions by half again\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = None  # Placeholder for the dynamically defined layer\n",
    "        self.classifier = None  # Placeholder for the classifier layer\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through feature extractor\n",
    "        x = self.features(x)\n",
    "\n",
    "        # Dynamically calculate flattened size for fully connected layer\n",
    "        if self.fc1 is None:\n",
    "            flattened_size = x.shape[1] * x.shape[2] * x.shape[3]\n",
    "            self.fc1 = nn.Linear(flattened_size, 512).to(x.device)\n",
    "            self.classifier = nn.Linear(512, self.num_classes).to(x.device)\n",
    "\n",
    "        # Flatten and pass through fully connected layers\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 17\n",
    "model = FaceClassifier(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('../models/', exist_ok=True)\n",
    "\n",
    "# Dynamic epoch control\n",
    "while True:\n",
    "    try:\n",
    "        # Ask the user how many epochs to run\n",
    "        num_epochs = int(input(\"How many epochs would you like to train for? (Enter 0 to stop): \"))\n",
    "        if num_epochs <= 0:\n",
    "            print(\"Training stopped by user.\")\n",
    "            break\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for images, labels in tqdm(train_loader, desc=f'Epoch {epoch} - Training loop'):\n",
    "                # Move inputs and labels to the device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            train_loss = running_loss / len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader, desc=f'Epoch {epoch} - Validation loop'):\n",
    "                    # Move inputs and labels to the device\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            val_loss = running_loss / len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Epoch {epoch}/{num_epochs} - Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Save the best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "                model_path = f\"../models/model_{timestamp}.pth\"\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                print(f\"New best model saved at {model_path}\")\n",
    "\n",
    "            # Update the scheduler\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Completed {num_epochs} epochs.\")\n",
    "    \n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# Function to display an image\n",
    "def imshow(img, title=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis(\"off\")\n",
    "    if title:\n",
    "        plt.title(title, fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "# Get 5 random images from the test_loader\n",
    "def get_random_images(data_loader, num_images=5):\n",
    "    data_iter = iter(data_loader)\n",
    "    images, labels = next(data_iter)  # Get a batch\n",
    "    indices = random.sample(range(len(images)), num_images)  # Select `num_images` random indices\n",
    "    return images[indices], labels[indices]\n",
    "\n",
    "# Load class names from the training folder\n",
    "train_folder = \"../data/people/\"\n",
    "classes = sorted([d for d in os.listdir(train_folder) if os.path.isdir(os.path.join(train_folder, d))])\n",
    "print(f\"Classes: {classes}\")\n",
    "\n",
    "# Get random images and their labels\n",
    "random_images, true_labels = get_random_images(test_loader, num_images=5)\n",
    "\n",
    "# Display images and ground truth\n",
    "grid = torchvision.utils.make_grid(random_images, nrow=5, padding=2, normalize=True)\n",
    "imshow(grid, title=\"Ground Truth: \" + ', '.join(classes[label] for label in true_labels))\n",
    "\n",
    "# Model predictions\n",
    "random_images = random_images.to(device)\n",
    "true_labels = true_labels.to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(random_images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Display predicted labels\n",
    "print('Predicted: ', ', '.join(f'{classes[predicted[j]]}' for j in range(len(predicted))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, transform):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return image, transform(image).unsqueeze(0)\n",
    "\n",
    "def predict(model, image_tensor, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        image_tensor = image_tensor.to(device)\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "    return probabilities.cpu().numpy().flatten()\n",
    "\n",
    "# Visualization\n",
    "def visualize_predictions(original_image, probabilities, class_names):\n",
    "    fig, axarr = plt.subplots(1, 2, figsize=(14, 7))\n",
    "    \n",
    "    # Display image\n",
    "    axarr[0].imshow(original_image)\n",
    "    axarr[0].axis(\"off\")\n",
    "    \n",
    "    # Display predictions\n",
    "    axarr[1].barh(class_names, probabilities)\n",
    "    axarr[1].set_xlabel(\"Probability\")\n",
    "    axarr[1].set_title(\"Class Predictions\")\n",
    "    axarr[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "image_paths = [os.path.join(\"../data/people/Robert Downey Jr\", f) for f in os.listdir(\"../data/people/Robert Downey Jr\")]\n",
    "\n",
    "for i in range(5):\n",
    "    original_image, image_tensor = preprocess_image(image_paths[i], transform)\n",
    "\n",
    "    # Make predictions\n",
    "    probabilities = predict(model, image_tensor, device)\n",
    "\n",
    "    # Visualize the predictions\n",
    "    visualize_predictions(original_image, probabilities, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "def generate_pairs(test_folder, valid_folder, max_pairs=5000):\n",
    "    positive_pairs = []\n",
    "    negative_pairs = []\n",
    "    \n",
    "    # Combine test and validation folders\n",
    "    all_folders = [test_folder, valid_folder]\n",
    "    \n",
    "    # Get the classes from the test and validation folders\n",
    "    class_folders = {}\n",
    "    for folder in all_folders:\n",
    "        class_folders[folder] = os.listdir(folder)\n",
    "    \n",
    "    # Create a dictionary to combine test and validation images for each class\n",
    "    combined_classes = {}\n",
    "    for folder in all_folders:\n",
    "        for class_name in class_folders[folder]:\n",
    "            class_path = os.path.join(folder, class_name)\n",
    "            images = os.listdir(class_path)\n",
    "            \n",
    "            if class_name not in combined_classes:\n",
    "                combined_classes[class_name] = []\n",
    "            combined_classes[class_name].extend([os.path.join(class_path, img) for img in images])\n",
    "    \n",
    "    # Now we have the combined images for each class, let's generate pairs\n",
    "    for _ in tqdm(range(max_pairs), desc=\"Generating pairs\"):\n",
    "        # Randomly choose a class that has images from both test and validation\n",
    "        class_name = random.choice(list(combined_classes.keys()))\n",
    "        images = combined_classes[class_name]\n",
    "\n",
    "        # Create positive pair (same class, one image from test, one from validation)\n",
    "        if len(images) > 1:\n",
    "            img1, img2 = random.sample(images, 2)  # Randomly select 2 images for a positive pair\n",
    "            positive_pairs.append((img1, img2))\n",
    "        \n",
    "        # Create negative pair (different classes)\n",
    "        other_class_name = random.choice([name for name in combined_classes if name != class_name])\n",
    "        other_class_images = combined_classes[other_class_name]\n",
    "        \n",
    "        if len(other_class_images) > 0:\n",
    "            img1 = random.choice(images)  # Randomly select one image from the current class\n",
    "            img2 = random.choice(other_class_images)  # Randomly select one image from the other class\n",
    "            negative_pairs.append((img1, img2))\n",
    "    \n",
    "    print(f\"Generated {len(positive_pairs)} positive pairs and {len(negative_pairs)} negative pairs.\")\n",
    "    return positive_pairs, negative_pairs\n",
    "\n",
    "positive_pairs, negative_pairs = generate_pairs(test_folder, valid_folder, max_pairs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, positive_pairs, negative_pairs, transform, threshold=0.5):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_scores = []\n",
    "\n",
    "    def load_image(image_path):\n",
    "        from PIL import Image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        return transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for pair, label in [(positive_pairs, 1), (negative_pairs, 0)]:\n",
    "            for img1_path, img2_path in tqdm(pair, desc=f\"Testing {'Positive' if label == 1 else 'Negative'} Pairs\"):\n",
    "                img1 = load_image(img1_path)\n",
    "                img2 = load_image(img2_path)\n",
    "\n",
    "                # Compute embeddings\n",
    "                embedding1 = model(img1)\n",
    "                embedding2 = model(img2)\n",
    "\n",
    "                # Calculate distance\n",
    "                distance = F.pairwise_distance(embedding1, embedding2).item()\n",
    "                score = 1 - distance  # Higher score for closer embeddings\n",
    "\n",
    "                all_scores.append(score)\n",
    "                all_labels.append(label)\n",
    "\n",
    "    # Calculate FAR, FRR, and EER\n",
    "    fpr, tpr, thresholds = roc_curve(all_labels, all_scores)\n",
    "    fnr = 1 - tpr\n",
    "\n",
    "    # Calculate EER\n",
    "    eer_threshold = thresholds[(np.abs(fpr - fnr)).argmin()]\n",
    "    eer = fpr[(np.abs(fpr - fnr)).argmin()]\n",
    "    return fpr, fnr, eer, eer_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "fpr, fnr, eer, eer_threshold = test_model(model, positive_pairs, negative_pairs, transform)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, 1 - fnr, label=\"ROC Curve\")\n",
    "plt.scatter([eer], [1 - eer], color='red', label=f\"EER: {eer:.2f}\")\n",
    "plt.xlabel(\"False Positive Rate (FAR)\")\n",
    "plt.ylabel(\"True Positive Rate (1 - FRR)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Equal Error Rate (EER): {eer}\")\n",
    "print(f\"Threshold at EER: {eer_threshold}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
