{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Učitavanje potrebnih biblioteka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision scikit-learn matplotlib tqdm numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Učitavanje seta podataka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceDataset(Dataset):\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data = ImageFolder(data_dir, transform=transform)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data_folder = './data/people/'\n",
    "train_folder = './data/train/'\n",
    "valid_folder = './data/valid/'\n",
    "\n",
    "# Remove existing folders (if they exist)\n",
    "for folder in [train_folder, valid_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "\n",
    "# Create destination folders\n",
    "for folder in [train_folder, valid_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "for class_name in os.listdir(main_data_folder):\n",
    "    class_path = os.path.join(main_data_folder, class_name)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    images = os.listdir(class_path)\n",
    "\n",
    "    os.makedirs(os.path.join(train_folder, class_name), exist_ok=True)\n",
    "    os.makedirs(os.path.join(valid_folder, class_name), exist_ok=True)\n",
    "\n",
    "    valid_images = images[:20]\n",
    "    train_images = images[20:]\n",
    "\n",
    "    for img in train_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(train_folder, class_name, img))\n",
    "    for img in valid_images:\n",
    "        shutil.copy(os.path.join(class_path, img), os.path.join(valid_folder, class_name, img))\n",
    "\n",
    "    print(f\"Class {class_name}: {len(train_images)} train, {len(valid_images)} validation images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceDataset(train_folder, transform=train_transform)\n",
    "val_dataset = FaceDataset(valid_folder, transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treniranje modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False  # Freeze feature extractor\n",
    "\n",
    "# Replace classifier\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512 * 7 * 7, 256),  # Add intermediate layer\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, num_classes)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "os.makedirs('./models/', exist_ok=True)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        num_epochs = int(input(\"How many epochs would you like to train for? (Enter 0 to stop): \"))\n",
    "        if num_epochs <= 0:\n",
    "            print(\"Training stopped by user.\")\n",
    "            break\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            running_loss = 0.0\n",
    "            for images, labels in tqdm(train_loader, desc=f'Epoch {epoch} - Training loop'):\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            train_loss = running_loss / len(train_loader.dataset)\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            running_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for images, labels in tqdm(val_loader, desc=f'Epoch {epoch} - Validation loop'):\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_loss += loss.item() * labels.size(0)\n",
    "            \n",
    "            val_loss = running_loss / len(val_loader.dataset)\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            print(f\"Epoch {epoch}/{num_epochs} - Train loss: {train_loss:.4f}, Validation loss: {val_loss:.4f}\")\n",
    "\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            model_path = f\"./models/model_{timestamp}.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            print(f\"New model saved at {model_path}\")\n",
    "\n",
    "            scheduler.step(val_loss)\n",
    "\n",
    "        print(f\"Completed {num_epochs} epochs.\")\n",
    "    \n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.title(\"Loss over epochs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluacija modela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model from file\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False  # Freeze feature extractor\n",
    "\n",
    "# Replace classifier\n",
    "model.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512 * 7 * 7, 256),  # Add intermediate layer\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(256, num_classes)\n",
    ")\n",
    "model.load_state_dict(torch.load('./best_model.pth'))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model evaluation\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(val_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        all_probs.extend(probs.cpu().numpy()[:, 1])\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_labels = np.array(all_labels)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "# Calculate the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_probs, pos_label=1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Calculate the Equal Error Rate (EER)\n",
    "fnr = 1 - tpr  # False Negative Rate\n",
    "eer_idx = np.nanargmin(np.abs(fnr - fpr))  # Find the threshold where FPR is closest to FNR\n",
    "eer = fpr[eer_idx]\n",
    "eer_threshold = thresholds[eer_idx]\n",
    "\n",
    "# Calculate accuracy at the threshold where EER occurs\n",
    "predicted_labels = (all_probs >= eer_threshold).astype(int)\n",
    "accuracy = accuracy_score(all_labels, predicted_labels)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\", linewidth=2)\n",
    "plt.scatter([fpr[eer_idx]], [tpr[eer_idx]], color='red', label=f\"EER: {eer:.2f}\", zorder=5)\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Print EER, threshold, and accuracy\n",
    "print(f\"Equal Error Rate (EER): {eer:.2f}\")\n",
    "print(f\"Threshold at EER: {eer_threshold:.2f}\")\n",
    "print(f\"Accuracy at EER Threshold: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some random test images with predictions\n",
    "def imshow(image, title):\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    plt.imshow(image)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "# Get 8 random indices from the dataset\n",
    "random_indices = random.sample(range(len(val_dataset)), 8)\n",
    "\n",
    "# Create a Subset dataset with these indices\n",
    "random_subset = torch.utils.data.Subset(val_dataset, random_indices)\n",
    "random_loader = torch.utils.data.DataLoader(random_subset, batch_size=8, shuffle=False)\n",
    "\n",
    "# Get the random batch of images\n",
    "images, labels = next(iter(random_loader))\n",
    "\n",
    "images = images.to(device)\n",
    "\n",
    "# Get predictions\n",
    "outputs = model(images)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Display random images with predictions\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i in range(len(images)):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    imshow(images[i].cpu(), title=f\"Pred: {val_dataset.classes[preds[i]]}\\nTrue: {val_dataset.classes[labels[i]]}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
